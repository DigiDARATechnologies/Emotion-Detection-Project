# ğŸ­ Emotion Detection


Real-time emotion detection from video and audio using Flask, SocketIO, and machine learning.

## ğŸŒŸ Overview
This project brings emotion detection to life by analyzing video (facial expressions) and audio (voice tone) in real-time. Built with Flask and SocketIO, it features a sleek, scrollable web interface that displays detected emotions (e.g., "angry") with confidence scores in a dynamic bar chart. Whether you're uploading media files or using your webcam for live detection, this tool provides an intuitive way to explore emotions.

## âœ¨ Key Features
- Real-Time Analysis ğŸ•’: Detect emotions live via webcam or from uploaded video/audio files.
- Dual Input Processing ğŸ¥ğŸ™ï¸: Combines video and audio for more accurate emotion detection.
- Interactive Dashboard ğŸ“Š: Scrollable UI with start/stop controls, file uploads, and a confidence bar chart.
- Cross-Platform ğŸ’»: Works seamlessly on Windows with Python and a modern browser.

## ğŸš€ Getting Started
### Prerequisites
Ensure you have the following installed:

**Python 3.6+ ğŸ**
**Git** (to clone the repository) ğŸ“¦
A modern **web browser** (e.g., Chrome, Firefox) ğŸŒ

### Dependencies
The project relies on several Python libraries, listed in requirements.txt:

- Flask
- Flask-SocketIO
- eventlet
- numpy
- OpenCV (cv2)
- Chart.js (for the bar chart)

## Installation
  - 1. Clone the Repository ğŸ“¥
       ```bash
       git clone https://github.com/DigiDARATechnologies/Emotion-Detection-Project.git
       cd Emotion-Detection-Project
       ```
    2. Install Dependencies ğŸ› ï¸
       ```bash
       pip install -r requirements.txt
       ```
      If requirements.txt is missing, generate it:
      ```bash
      pip freeze > requirements.txt
      ```
    3. Run the Application ğŸš€
       ```bash
       python app.py
       ```
       - The server will start at http://127.0.0.1:5000/.
       - Open this URL in your browser to access the interface.

## ğŸ® Usage
1. Upload Files ğŸ“‚
   - Use the "Upload Video" or "Upload Audio" inputs to select files.
   - Click Upload Files to process and analyze emotions.
2. Start Live Detection ğŸ“¹
   - Click Start Live Detection to enable your webcam.
   - Watch as emotions (e.g., "angry") and confidence scores (e.g., 85%, 75%) update in real-time.
3. Stop Detection â¹ï¸
   - Click Stop Live Detection to end the webcam feed.
4. View Results ğŸ“ˆ
   - Emotions and confidence scores are displayed for video and audio inputs.
   - A bar chart visualizes the confidence levels for both sources.

## ğŸ“‚ Project Structure
 ```text
Emotion-Detection-Project/
â”œâ”€â”€ app.py                  # Flask backend with SocketIO for real-time processing
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # HTML, CSS, and JavaScript for the web interface
â”œâ”€â”€ haarcascade_frontalface_default.xml  # OpenCV face detection classifier
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore              # Excluded files (e.g., __pycache__, venv)
â”œâ”€â”€ README.md               # This file
```

## ğŸ¤ Contributing
We welcome contributions to enhance this project! Follow these steps:
  1. **Fork the Repository ğŸ´**
  2. **Create a Feature Branch ğŸŒ¿**
     ```bash
     git checkout -b feature/your-feature-name
     ```
  3. **Commit Your Changes ğŸ’¾**
     ```bash
     git commit -m "Add your feature description"
     ```
  4. **Push to Your Branch ğŸ“¤**
     ```bash
     git push origin feature/your-feature-name
     ```
  5. **Open a Pull Request ğŸ”„**

## ğŸ“œ License
This project is licensed under the MIT License. See the LICENSE file for details.

## ğŸ“¬ Contact
 - Maintainer: Ranjeeth11 (GitHub)
 - Organization: DigiDARATechnologies
 - Issues & Feedback: Open an issue

## ğŸ™Œ Acknowledgments
  - **Flask & SocketIO**: For enabling real-time web applications.
  - **OpenCV**: For face detection and video processing.
  - **Chart.js**: For the interactive bar chart visualization.
  - **Community**: Thanks to the open-source community for inspiration and support.
